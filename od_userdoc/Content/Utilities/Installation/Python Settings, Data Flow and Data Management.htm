<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head>
    </head>
    <body>
        <h2>9.4.3 Python Settings, Data Flow and Data Management<MadCap:keyword term="Python Settings, Data Flow and Data Management" /></h2>
        <p>The Python Settings Window is started from the Utilities -&gt; Installation -&gt; Python Settings Window.</p>
        <blockquote>
            <p>
                <img src="../../Resources/Images/Utilities/ml_set_pythin_settings.png" class="General_Image" style="width: 909px;height: 504px;" />
            </p>
        </blockquote>
        <p>OpendTect Machine Learning comes with its own Miniconda Python environment. Users who prefer to work in a private Python environment can change the <b>Python environment</b> here. If a <b>Custom</b> environment is selected you need to specify the root of the environment. The <b>Virtual</b> <b>environment</b>: odmlpython-cuda10 runs models on the GPU; odmlpython-cpu-mkl runs on the CPU. Computations on a GPU are many factors faster than computations on a CPU. If the GPU in your environment is too small for certain jobs to run you can switch virtual environments to CPU usage.</p>
        <p>The <b>Custom Module Path</b> is the path for Python developers in which they develop private Machine Learning Models in this environment. All models in the given directory, which are named: ‘<b>mlmodel</b>….” will appear in the UI of the Machine Learning Control Center and can thus be applied to other data sets.</p>
        <p>The <b>Python IDE Command</b> is the Python editor you wish to use. You can launch the IDE using the specified <b>Command</b>, Optionally with some <b>Arguments</b> from a <b>Python Command Window</b>. Alternatively, you can add an <b>icon</b> to your plugin toolbar by pressing the corresponding icon in this window. In this case the <b>Spyder icon</b> with Spyder <b>Tool Tip</b> is added to the icon toolbar.</p>
        <p>Pressing this icon from the toolbar will launch Spyder with the correct settings. The Python environment can be tested with the <b>Test icon</b>.</p>
        <p>The general flow of a Machine Learning workflow is as follows:</p>
        <ol>
            <li>Based on the data you have and the problem you want to solve: <b>Select a workflow</b> from the control center</li>
            <li><b>Create a Training Set</b>. Construction starts with a selection of the Target (output) feature. Next you select the input features and the dimensions of the input features. Training Sets can be constructed from real data over multiple surveys or from synthetic data (SynthRock). Training Sets selection files can be saved, restored and edited. Training Sets themselves are stored in <a href="https://en.wikipedia.org/wiki/Hierarchical_Data_Format" target="_blank">hdf5 format</a>. These files can be managed from the <b>Manage Machine Learning icon</b>.</li>
            <li><b>Select a Model</b>. Depending on the workflow the plugin supports Machine Learning Models from <b>Scikit Learn</b> and/or from <b>Keras (TensorFlow)</b>. Set the <b>Training</b> <b>Parameters</b> and train the model. A Test Set to monitor Overfitting is automatically split off from the Training Set by the software. Models are also stored in hdf5 format and can be managed from the <b>Manage Machine Learning icon</b>.</li>
            <li>Monitor training. This is done in a <b>log file</b> that outputs information about the loss and accuracy of the model for both Training and Test Sets. <b>Keras</b> models are also monitored graphically in <b>TensorBoard</b>, which is started in your default browser when training starts. Models can be trained from scratch (<b>New</b>), continued from a stored model (<b>Restore</b>) and continued from a trained model with new data (<b>Transfer</b>). In Transfer training the convolutional parts of a deep learning model are not updated to safe time. Only the weights of the last layer are updated with the new training examples.</li>
            <li><b>Apply</b> the trained model. Select the input data set(s) on which the trained models will be applied.</li>
        </ol>
        <p>&#160;</p>
        <p>Training Sets can be <b>managed</b> in the “Machine Learning Deep Example Sets” window that is launched from all windows with a “Manage Example Sets” icon <img src="../Resources/Images/Utilities/ml_manage_example_sets_icon.png" class="Icons" />  next to a Select button. The “Machine Learning Deep Example Sets” window pops up.</p>
        <blockquote>
            <p>
                <img src="../../Resources/Images/Utilities/ml_manage_deep_learning_example_sets.png" style="width: 843px; height: 645px;" class="General_Image" />
            </p>
        </blockquote>
        <p>In this window you can use the corresponding icons in the ribbon on the right to rename, lock, remove and set defaults. The info box in the middle gives detailed information on the file. Personal textual information can be added in the bottom field. Press the save button to save this information with the file.</p>
        <p>Example data sets can be viewed with an <b>hdf5</b> viewer that is launched from all windows with the “View Example Sets” icon <img src="../Resources/Images/Utilities/ml_view_example_sets_icon.png" class="Icons" />  next to the “Manage Example Sets” icon. The “View Example Sets“ viewer pops up.</p>
        <blockquote>
            <p>
                <img src="../../Resources/Images/Utilities/ml_view_example_sets_window.png" style="width: 917px;height: 1046px;" />
            </p>
            <p>&#160;</p>
        </blockquote>
        <p>The hdf5 viewer is a <b>2D viewer</b> that allows you to inspect 2D and 3D input - and target images. Use the sliders to select the input <b>attribute</b> (typically 1, but more are possible) and the <b>input</b> image to view. In the case of 3D images (3D cubelets) you can slide through the selected cubelet in the inline, crossline and Z directions with 3 additional sliders.</p>
        <p>The display can be changed by changing the <b>color palette</b> and the <b>zoom factor</b>.</p>
        <p>Note, the hdf5 viewer is developed in Bokeh, a Python library for interactive displays. The icons above the image are standard <b>Bokeh plot icons</b> to control zoom, pan, reset etc.</p>
        <p>The <b>Bokeh server icons</b> in the ribbon on the right-hand side of the viewer can be used to start, stop and  restart the Bokeh server in case something goes wrong. The Bokeh server is a separate process that is started by OpendTect. Information about this process is given in the log file that can be inspected by pressing the corresponding icon.</p>
        <p>&#160;</p>
    </body>
</html>