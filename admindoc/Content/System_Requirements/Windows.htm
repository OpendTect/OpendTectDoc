<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head>
    </head>
    <body>
		<MadCap:conditionalText MadCap:conditions="Default.ScreenOnly"><h1>Windows</h1></MadCap:conditionalText>
        <MadCap:conditionalText MadCap:conditions="Default.PrintOnly"><p></p><h2 style="page-break-before: avoid">Windows</h2></MadCap:conditionalText>
		<MadCap:conditionalText MadCap:conditions="Default.ScreenOnly"><h2>Minimum</h2></MadCap:conditionalText>
        <MadCap:conditionalText MadCap:conditions="Default.PrintOnly"><p></p><h3 style="page-break-before: avoid">Minimum</h3></MadCap:conditionalText>
        <ul>
            <li><b>Version</b>:&#160;8.1/10<br /><br /></li>
            <li><b>CPU</b>:&#160;Intel/AMD, 64 bits<br /><br /></li>
            <li><b>GPU</b>:&#160;Basic Intel graphics cards or Nvidia (e.g. recent GeForce/Quadro/NVS series) graphics cards; AMD graphics cards may work.<br /><br /></li>
            <li><b>Memory</b>:&#160;8 GB of RAM, OpendTect itself needs at least 2 GB RAM. Therefore, 8 GB will almost certainly be the absolute minimum.<br /><br /></li>
            <li><b>Storage</b>:&#160;Hard Disk</li>
        </ul>
		<MadCap:conditionalText MadCap:conditions="Default.ScreenOnly"><h2>Recommended</h2></MadCap:conditionalText>
        <MadCap:conditionalText MadCap:conditions="Default.PrintOnly"><p></p><h3 style="page-break-before: avoid">Recommended</h3></MadCap:conditionalText>
        <ul>
            <li><b>Version</b>: 8.1/10<br /><br /></li>
            <li><b>CPU</b>: Intel/AMD processor with 64 bit support, 3+&#160;GHz multi-core. <br />Note that OpendTect uses all processors if necessary. The more cores and speed, the better. OpendTect will automatically use multiple threads in many situations. This depends on the type of attribute, display, etc. We put a lot of effort to get time-consuming tasks  multi-threaded.<br /><br /></li>
            <li><b>GPU</b>: Nvidia (e.g. recent main-stream up to high-end GeForce series) graphics cards. <br />Quadro or NVS series cards could give the bit extra you want. In doubt, buy the best GeForce card you can find. When buying a laptop make sure that it has a Nvidia chipset.<br /><br /></li>
            <li><b>Memory</b>: on the safe side don't go for less than 32 GB. <br />Buy as much memory that you can afford and fits in the system. The big clients for example use nothing less than 512 GB.<br /><br /></li>
            <li><b>Storage</b>: SSD is best, other good options are Hard Disk and Network Drive. <br />This is usually under-valued, but it's often the crucial performance component. SSD disks will give a tremendous boost in performance; essentially, data on SSD disks loads almost as fast as pre-loaded, in-memory data. Performance could be miserable if data needed to stream through (relatively) slow disks and/or networks.</li>
        </ul>
		<MadCap:conditionalText MadCap:conditions="Default.ScreenOnly"><h2>For Machine Learning</h2></MadCap:conditionalText>
        <MadCap:conditionalText MadCap:conditions="Default.PrintOnly"><p></p><h3 style="page-break-before: avoid">For Machine Learning</h3></MadCap:conditionalText>
        <ul>
            <li><b>Version</b>:&#160;8.1/10<br /><br /></li>
            <li><b>CPU</b>: Intel, 64 bits for when using Python environment  <i>Intel™ Math Kernel - MKL</i> for Machine Learning using CPU only. AMD, 64 bits should be fine when using the Python Environment with <i>CUDA 10.1</i> for Machine&#160;Learning on the GPU.<br />Ideally you want the system to be expendable to 4 GPUs. The CPU will need to support all GPUs.  Important to look for is how many PCIe lanes the CPU supports and how many PCIe lanes are needed for the system's number of GPUs and M.2 NVMe SSDs. We recommend to get a CPU with at least 8 cores, 16 threads and 40 PCIe lanes.<br /><br /></li>
            <li><b>GPU</b>: Nvidia, GeForce or Quadro series. <br />The GPU needs to be fast enough and able to fit the model and data batch in memory. When in doubt choose the one with more memory.&#160;Other things to look for is the number of CUDA cores, tensor cores and GB memory bandwidth per second. We recommend the following cards:<ul><li>Nvidia GeForce RTX 2080 Ti with 11 GB DDR6 memory</li><li>Nvidia Quadro RTX 6000 with 24 GB DDR6 memory</li><li>Nvidia Quadro RTX 8000 with 48 GB DDR6 memory<br /><br /></li></ul></li>
            <li><b>Memory</b>: DDR4 memory, don't go for less than 32 GB. <br />Buy as much memory that you can afford and fits in the system.<br /><br /></li>
            <li><b>Storage</b>:&#160;The best choice is M.2 NVMe SSD that is big enough for the data. <br />The advantage of M.2&#160;NMVe SSD is that it is plugged into the motherboard and is super fast. Other options are SATA SSD, Hard Disk and Network Drive. Performance could be miserable if data needed to stream through (relatively) slow disks and/or networks.<br /></li>
        </ul>
        <p><i>Please note that:</i>
        </p>
        <ul>
            <li><i>For best performance OpenGL&#160;drivers should be up-to-date. For Machine Learning on GPU we provide a Python package with CUDA 10.1. Please see this <a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#cuda-major-component-versions__table-cuda-toolkit-driver-versions" target="_blank">table</a> on the Nvidia CUDA&#160;Tookit documentation page for the minimum compatible driver version.</i>
                <br />
                <br />
            </li>
            <li><i>Windows needs to be updated with the latest updates from Microsoft.</i>
            </li>
        </ul>
    </body>
</html>